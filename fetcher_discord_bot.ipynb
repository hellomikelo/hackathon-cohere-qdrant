{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hellomikelo/hackathon-cohere-qdrant/blob/main/fetcher_discord_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJbCW_oL0GkB"
      },
      "source": [
        "# Discord bot deployment\n",
        "\n",
        "This notebook goes through the steps to \n",
        "\n",
        "1. Set up FastAPI to query vector search engine\n",
        "2. Deploy Discord bot to Deta space"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!printf \"py-cord \\ndatasets \\nqdrant_client==\"0.11.0\" \\ncohere \\npython-dotenv \\ntime-uuid\" > requirements.txt"
      ],
      "metadata": {
        "id": "LxwUP0QYqGZt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paRVNeYuqJf4",
        "outputId": "31e221c0-da89-493e-a4ae-084383a78105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for time-uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.22.1 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 4.22.1 which is incompatible.\n",
            "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX7gRmoPu2FH",
        "outputId": "e7579aa6-abdf-4c14-9d3e-bb7b34027d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Oo2TySlz88R2"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/env/vars.env /content/.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1HBMoNkzu2FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f656998-298c-48d9-da81-8157fbee36f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect Discord chat history\n",
        "\n",
        "Get Discord channel chat history and save them as CSV. This uses the [Message components](https://discordpy.readthedocs.io/en/stable/api.html#message) ."
      ],
      "metadata": {
        "id": "m4q-h_Tar4qt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isRYnL4UwMTm",
        "outputId": "bc24642d-79fa-4cb1-9ab1-c57fd9921d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting get_chat_history.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile get_chat_history.py\n",
        "import discord\n",
        "import pandas as pd\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "bot = discord.Bot()\n",
        "\n",
        "# Google Drive path\n",
        "CHAT_HISTORY_PATH = '/content/drive/MyDrive/career/projects/hackathons/lablab-cohere-qdrant-hackathon/discord-chat-history.csv'\n",
        "\n",
        "@bot.event\n",
        "async def on_ready():\n",
        "    print(f\"{bot.user} is ready and online!\")\n",
        "    \n",
        "bot.run(os.getenv('DISCORD_TOKEN'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 get_chat_history.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0QnjzySt3lr",
        "outputId": "a8be82bf-65a1-4f6b-bb68-eb2532979e4e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetcher#2073 is ready and online!\n",
            "Chat history saved to /content/drive/MyDrive/career/projects/hackathons/lablab-cohere-qdrant-hackathon/discord-chat-history.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "ZAUXnPlRgjaD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "CHAT_HISTORY_PATH = '/content/drive/MyDrive/career/projects/hackathons/lablab-cohere-qdrant-hackathon/discord-chat-history.csv'\n",
        "df = pd.read_csv(CHAT_HISTORY_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "H5EOyRWygzxP",
        "outputId": "f0a53dbd-0982-4c6e-9570-1daba3d60707"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                            content  \\\n",
              "0           0  https://discord.com/api/oauth2/authorize?clien...   \n",
              "1           1                                                NaN   \n",
              "2           2                                                NaN   \n",
              "3           3                       <@1084320048530862160> hello   \n",
              "4           4                         this is a test for the bot   \n",
              "\n",
              "                         created_at     author  \\\n",
              "0  2023-03-13 15:46:21.051000+00:00     likemo   \n",
              "1  2023-03-13 15:46:45.089000+00:00    Fetcher   \n",
              "2  2023-03-13 15:48:52.009000+00:00  kiritoku_   \n",
              "3  2023-03-13 16:01:22.527000+00:00     likemo   \n",
              "4  2023-03-13 16:02:45.727000+00:00     likemo   \n",
              "\n",
              "                                            jump_url            author_id  \\\n",
              "0  https://discord.com/channels/10848649878870549...   638456119039361035   \n",
              "1  https://discord.com/channels/10848649878870549...  1084320048530862160   \n",
              "2  https://discord.com/channels/10848649878870549...   524207009122222080   \n",
              "3  https://discord.com/channels/10848649878870549...   638456119039361035   \n",
              "4  https://discord.com/channels/10848649878870549...   638456119039361035   \n",
              "\n",
              "                msg_id           channel_id             guild_id  \n",
              "0  1084865038730408026  1084864988688154627  1084864987887054919  \n",
              "1  1084865139553091614  1084864988688154627  1084864987887054919  \n",
              "2  1084865671894143136  1084864988688154627  1084864987887054919  \n",
              "3  1084868819794788553  1084864988688154627  1084864987887054919  \n",
              "4  1084869168760885448  1084864988688154627  1084864987887054919  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32b94033-9b89-4a4d-8b62-e5493efd768f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>content</th>\n",
              "      <th>created_at</th>\n",
              "      <th>author</th>\n",
              "      <th>jump_url</th>\n",
              "      <th>author_id</th>\n",
              "      <th>msg_id</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>guild_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>https://discord.com/api/oauth2/authorize?clien...</td>\n",
              "      <td>2023-03-13 15:46:21.051000+00:00</td>\n",
              "      <td>likemo</td>\n",
              "      <td>https://discord.com/channels/10848649878870549...</td>\n",
              "      <td>638456119039361035</td>\n",
              "      <td>1084865038730408026</td>\n",
              "      <td>1084864988688154627</td>\n",
              "      <td>1084864987887054919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-03-13 15:46:45.089000+00:00</td>\n",
              "      <td>Fetcher</td>\n",
              "      <td>https://discord.com/channels/10848649878870549...</td>\n",
              "      <td>1084320048530862160</td>\n",
              "      <td>1084865139553091614</td>\n",
              "      <td>1084864988688154627</td>\n",
              "      <td>1084864987887054919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023-03-13 15:48:52.009000+00:00</td>\n",
              "      <td>kiritoku_</td>\n",
              "      <td>https://discord.com/channels/10848649878870549...</td>\n",
              "      <td>524207009122222080</td>\n",
              "      <td>1084865671894143136</td>\n",
              "      <td>1084864988688154627</td>\n",
              "      <td>1084864987887054919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>&lt;@1084320048530862160&gt; hello</td>\n",
              "      <td>2023-03-13 16:01:22.527000+00:00</td>\n",
              "      <td>likemo</td>\n",
              "      <td>https://discord.com/channels/10848649878870549...</td>\n",
              "      <td>638456119039361035</td>\n",
              "      <td>1084868819794788553</td>\n",
              "      <td>1084864988688154627</td>\n",
              "      <td>1084864987887054919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>this is a test for the bot</td>\n",
              "      <td>2023-03-13 16:02:45.727000+00:00</td>\n",
              "      <td>likemo</td>\n",
              "      <td>https://discord.com/channels/10848649878870549...</td>\n",
              "      <td>638456119039361035</td>\n",
              "      <td>1084869168760885448</td>\n",
              "      <td>1084864988688154627</td>\n",
              "      <td>1084864987887054919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b94033-9b89-4a4d-8b62-e5493efd768f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32b94033-9b89-4a4d-8b62-e5493efd768f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32b94033-9b89-4a4d-8b62-e5493efd768f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "df.head()\n",
        "# df.shape\n",
        "# df.query(\"author == 'journeyman'\")\n",
        "# df.content.fillna('').apply(lambda x: len(x.split(' ')))\n",
        "# df.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create message vector embeddings\n",
        "\n",
        "References: \n",
        "* Notebook for [Cohere and Qdrant Multilingual Semantic Search Hackathon](https://lablab.ai/event/multilingual-semantic-search-hackathon). \n",
        "* Sampled from [Question Answering as a Service with Cohere and Qdrant](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/). \n",
        "* Also see [Neural Search Tutorial](https://qdrant.tech/articles/neural-search-tutorial/).\n",
        "* [Qdrant quickstart](https://qdrant.tech/documentation/quick_start)"
      ],
      "metadata": {
        "id": "miJJ8XUixK8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile embed_chat_history.py\n",
        "import discord\n",
        "import pandas as pd\n",
        "import os\n",
        "import time_uuid\n",
        "\n",
        "import cohere\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client import models\n",
        "from qdrant_client.http import models as rest\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "QDRANT_CLOUD_HOST = \"19531f2c-0717-4706-ac90-bd8dd1a6b0cc.us-east-1-0.aws.cloud.qdrant.io\"\n",
        "QDRANT_COLLECTION_NAME = 'discord'\n",
        "# Google Drive path\n",
        "CHAT_HISTORY_PATH = '/content/drive/MyDrive/career/projects/hackathons/lablab-cohere-qdrant-hackathon/discord-chat-history.csv'\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "cohere_client = cohere.Client(os.getenv('COHERE_API_KEY'))\n",
        "qdrant_client = QdrantClient(\n",
        "    host=QDRANT_CLOUD_HOST, \n",
        "    prefer_grpc=False,\n",
        "    api_key=os.getenv('QDRANT_API_KEY'),\n",
        ")\n",
        "\n",
        "    \n",
        "def clean_chat(df):\n",
        "    \"\"\"Clean chat history to keep only alphanums and Han Ideographs.\"\"\"\n",
        "    _df = df.copy()\n",
        "    _df['content'] = (_df['content']\n",
        "                      .str.replace('[^a-zA-Z\\u4E00-\\u9FFF\\s]', '', regex=True)\n",
        "                      .str.replace('(http\\w+|\\n)', '', regex=True)\n",
        "                      .str.replace('<.*>', '', regex=True)\n",
        "                      .str.lower()\n",
        "                      .str.strip()\n",
        "                      .fillna('')\n",
        "                      )\n",
        "    _df['id'] = _df.created_at.apply(lambda x: str(time_uuid.TimeUUID.with_utc(pd.to_datetime(x))))\n",
        "    _df['word_count'] = _df.content.apply(lambda x: len(x.split(' ')))\n",
        "    return _df\n",
        "\n",
        "\n",
        "def create_embeddings(dataset: pd.DataFrame):\n",
        "\n",
        "    # Embed chat messages\n",
        "    embeddings = cohere_client.embed(\n",
        "        texts=dataset.content.tolist(),\n",
        "        model='multilingual-22-12',\n",
        "    )\n",
        "\n",
        "    vector_size = len(embeddings.embeddings[0])\n",
        "    vectors = [list(map(float, vector)) for vector in embeddings.embeddings]\n",
        "\n",
        "    ids = dataset.id.tolist()\n",
        "\n",
        "    # Create Qdrant vector database collection\n",
        "    qdrant_client.recreate_collection(\n",
        "        collection_name=QDRANT_COLLECTION_NAME,\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=vector_size, \n",
        "            distance=rest.Distance.DOT # for multilingual model\n",
        "            # distance=rest.Distance.COSINE # for large model\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Upsert new embeddings into vector search engine\n",
        "    qdrant_client.upsert(\n",
        "        collection_name=QDRANT_COLLECTION_NAME, \n",
        "        points=rest.Batch(\n",
        "            ids=ids,\n",
        "            vectors=vectors,\n",
        "            payloads=dataset.to_dict(orient='records'),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print('Vector database created.')\n",
        "\n",
        "\n",
        "def test_embed():\n",
        "    # Test query embeddings\n",
        "    new_embeddings = cohere_client.embed(\n",
        "        texts=[\"discussions on horses\", \"discussions on asian countries\", \"interesting dog facts\"],\n",
        "        # model=\"large\",\n",
        "        model='multilingual-22-12',\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "    k_max = 5\n",
        "\n",
        "    new_vectors = [list(map(float, vector)) for vector in new_embeddings.embeddings]\n",
        "\n",
        "    for embedding in new_vectors:\n",
        "        response = qdrant_client.search(\n",
        "            collection_name=QDRANT_COLLECTION_NAME,\n",
        "            query_vector=embedding,\n",
        "            limit=k_max,\n",
        "        )\n",
        "        results.append([record.payload['content'] for record in response])\n",
        "    print(results)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    df = pd.read_csv(CHAT_HISTORY_PATH, index_col=0)\n",
        "    dataset = clean_chat(df)\n",
        "    embed = True\n",
        "    if embed:\n",
        "        create_embeddings(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnjECNh5xNu3",
        "outputId": "07b74537-0d3e-490d-bd2e-4cee51fd7bfd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting embed_chat_history.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 embed_chat_history.py"
      ],
      "metadata": {
        "id": "9GX-wNdQzu1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacb8670-0243-4278-a53d-9d5cea284be2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector database created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wEGz83hh2-E",
        "outputId": "24057bd2-38fc-457a-cfed-c164c5984a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fetcher.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile fetcher.py\n",
        "import discord\n",
        "from discord.ext.commands import slash_command\n",
        "from discord.ext import commands\n",
        "from discord.ext.commands import Cog\n",
        "\n",
        "import os \n",
        "import regex as re\n",
        "from dotenv import load_dotenv\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cohere\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client import models\n",
        "from qdrant_client.http import models as rest\n",
        "from qdrant_client.models import Filter\n",
        "\n",
        "\n",
        "load_dotenv()  # load all the variables from the env file\n",
        "\n",
        "CHAT_HISTORY_PATH = '/content/drive/MyDrive/career/projects/hackathons/lablab-cohere-qdrant-hackathon/discord-chat-history.csv'\n",
        "BASE_MESSAGE_URL = \"https://discord.com/channels/{guild_id}/{channel_id}/{message_id}\"\n",
        "QDRANT_CLOUD_HOST = \"19531f2c-0717-4706-ac90-bd8dd1a6b0cc.us-east-1-0.aws.cloud.qdrant.io\"\n",
        "QDRANT_COLLECTION_NAME = 'discord'\n",
        "\n",
        "co = cohere.Client(os.getenv('COHERE_API_KEY'))\n",
        "qdrant_client = QdrantClient(\n",
        "    host=QDRANT_CLOUD_HOST, \n",
        "    prefer_grpc=False,\n",
        "    api_key=os.getenv('QDRANT_API_KEY'),\n",
        ")\n",
        "discord_client = discord.Client()\n",
        "bot = discord.Bot()\n",
        "\n",
        "def embed_text(text: list, model='multilingual-22-12'):\n",
        "    \"\"\"Generate text embeddings.\"\"\"\n",
        "    if type(text) is str:\n",
        "        text = [text]\n",
        "    embeddings = co.embed(text, model=model)\n",
        "    vectors = [list(map(float, vector)) for vector in embeddings.embeddings]\n",
        "    return vectors\n",
        "\n",
        "\n",
        "@bot.event\n",
        "async def on_ready():\n",
        "    print(f\"{bot.user} is ready and online!\")\n",
        "\n",
        "# Define a search filter for author\n",
        "ignore_author = \"Fetcher\"\n",
        "author_filter = Filter(**{\"must_not\": [{\"key\": \"author\", \"match\": {\"value\": \"Fetcher\"}},\n",
        "                                       {\"key\": \"author\", \"match\": {\"value\": \"Findio\"}},\n",
        "                                       {\"key\": \"author\", \"match\": {\"value\": \"Chatter\"}},\n",
        "                                       ],\n",
        "                       \"must\": [{ \"key\": \"word_count\", \"range\": { \"gte\": 3 }}]\n",
        "                       })\n",
        "\n",
        "@bot.slash_command(name=\"fetch\", description=\"Search for messages by embedding\")\n",
        "async def fetch(ctx, query: str, k_max=5):\n",
        "    min_words = 20\n",
        "    vectors = embed_text(query)\n",
        "    for vector in vectors:\n",
        "        response = qdrant_client.search(\n",
        "            collection_name=QDRANT_COLLECTION_NAME,\n",
        "            query_vector=vector,\n",
        "            query_filter=author_filter,\n",
        "            limit=k_max,\n",
        "        )\n",
        "    results = [record.payload for record in response]\n",
        "\n",
        "    # def get_plain(content: str):\n",
        "    #     plain = re.sub(r'\\n', ' \\n', content)\n",
        "    #     plain = re.sub(r'(>.*\\n|```(.|\\n)*```|`?|\\n)', '', plain.lower().strip())\n",
        "    #     return plain\n",
        "\n",
        "    if len(results) > 0:\n",
        "        output = []\n",
        "        # result_str = f'Search query: \"{query}\":\\nSearch results:\\n'\n",
        "        # for result in results:\n",
        "            # TODO: summarize by thread not single messages\n",
        "            # if len(result['content'].split()) >= min_words:\n",
        "            #     summary = co.summarize( \n",
        "            #         text=result['content'],\n",
        "            #         model='summarize-xlarge', \n",
        "            #         length='medium',\n",
        "            #         extractiveness='low',\n",
        "            #         temperature=0.3,\n",
        "            #         additional_command=\"to remember a conversation\"\n",
        "            #     ).summary\n",
        "            # else: \n",
        "            #     summary = result['content']\n",
        "\n",
        "            # result_message = result['content']\n",
        "            # if len(result_message) > 100:\n",
        "            #     result_message = result_message[:100] + '...'\n",
        "                \n",
        "            # result_str += f\"\"\"\n",
        "            # * {result['author']} wrote [{result['created_at'][:16]}]: \n",
        "            # [{result_message}]({result['jump_url']}) \n",
        "            # {result['guild_id']}/{result['channel_id']}/{result['msg_id']}\n",
        "            # \"\"\"\n",
        "\n",
        "        embed=discord.Embed(color=0x1eff00)\n",
        "        for result in results:\n",
        "            embed.add_field(name=f\"{result['author']} at {result['created_at'][:16]}\\n{result['channel_id']}.{result['msg_id']}\", \n",
        "                            value=f\"[{result['content'][:200]}...]({result['jump_url']})\", \n",
        "                            inline=False)\n",
        "        embed.set_footer(text=\"Use `/discuss` to message user on this topic.\")\n",
        "\n",
        "        # await ctx.respond(content=result_str)\n",
        "        await ctx.respond(f':wave: Your search results for \"{query}\"', embed=embed)\n",
        "    else:\n",
        "        await ctx.respond(\"No matching messages found.\")\n",
        "\n",
        "\n",
        "@bot.slash_command(name=\"revise\", description=\"Revise sentence for clarity\")\n",
        "async def revise(ctx, sentence: str):\n",
        "    \"\"\"Use generate API to revise sentence.\"\"\"\n",
        "    \n",
        "    prompt = f\"Give me a better version of the following sentence that is more concise and clear, in a polite, fun, yet professional tone: {sentence}\" \n",
        "    response = co.generate(model='command-xlarge-beta',  \n",
        "                        prompt = prompt,  \n",
        "                        max_tokens=90,  \n",
        "                        temperature=0.5,  \n",
        "                        )\n",
        "    revised = response.generations[0].text\n",
        "    await bot.wait_until_ready()\n",
        "    if revised:\n",
        "        embed=discord.Embed(color=0x1eff00)\n",
        "        embed.add_field(name=\"Original\", value=sentence, inline=False)\n",
        "        embed.add_field(name=\"Revised\", value=revised, inline=False)\n",
        "        await ctx.respond(\":wave: Here you go.\", embed=embed)\n",
        "        # await ctx.respond(content=f\"__Old__:\\n{sentence}\\n__Revised__: {revised}\")\n",
        "    else:\n",
        "        await ctx.respond(content=\"No revision available.\") \n",
        "\n",
        "\n",
        "@bot.slash_command(name=\"discuss\", description=\"Start a conversation on a topic.\")\n",
        "async def start_convo(ctx: discord.ApplicationContext, user, id: str):\n",
        "    try: \n",
        "        channel_id, msg_id = id.split('.')\n",
        "        try: \n",
        "            # Get the message\n",
        "            msg = await ctx.fetch_message(int(msg_id))\n",
        "        except: \n",
        "            # Try to get the thread's parent channel\n",
        "            msg = await ctx.fetch_message(int(channel_id))\n",
        "\n",
        "        def get_plain_thread(content: str):\n",
        "            plain = re.sub(r'\\n', ' \\n', content)\n",
        "            plain = re.sub(r'(>.*\\n|```(.|\\n)*```|`?|\\n)', '', plain.lower().strip())\n",
        "            return plain\n",
        "        \n",
        "        plain_thread = get_plain_thread(msg.content) + ' '\n",
        "        thread_summary = ''\n",
        "        if msg.flags.has_thread:\n",
        "            async for m in msg.thread.history(limit=100, oldest_first=True):\n",
        "                formatted_content = m.content\n",
        "                plain_thread += get_plain_thread(formatted_content) + ' '\n",
        "        else: \n",
        "            pass\n",
        "\n",
        "        thread_summary = co.summarize(\n",
        "            text=plain_thread,\n",
        "            model='summarize-xlarge', \n",
        "            length='medium',\n",
        "            extractiveness='low',\n",
        "            temperature=0.3,\n",
        "            additional_command=\"to remember a conversation\"\n",
        "        ).summary\n",
        "        \n",
        "        embed=discord.Embed(color=0x1eff00)\n",
        "        embed.add_field(name=f\"Original message thread\", value=f\"[{msg.content[:200]}...]({msg.jump_url})\", inline=False)\n",
        "        embed.add_field(name=f\"TL;DR\", value=thread_summary, inline=False)\n",
        "        await ctx.respond(f':wave: {user}, <@{ctx.author.id}> wants to chat with you about below.', embed=embed)\n",
        "    except:\n",
        "        await ctx.respond(\"No message found.\")\n",
        "\n",
        "\n",
        "@bot.slash_command(name=\"getthread\", description=\"Summarize a thread or message.\")\n",
        "async def get_thread(ctx: discord.ApplicationContext, id):\n",
        "    try: \n",
        "        channel_id, msg_id = id.split('.')\n",
        "        try: \n",
        "            # Get the message\n",
        "            msg = await ctx.fetch_message(int(msg_id))\n",
        "        except: \n",
        "            # Try to get the thread's parent channel\n",
        "            msg = await ctx.fetch_message(int(channel_id))\n",
        "\n",
        "        def get_plain_thread(content: str):\n",
        "            plain = re.sub(r'\\n', ' \\n', content)\n",
        "            plain = re.sub(r'(>.*\\n|```(.|\\n)*```|`?|\\n)', '', plain.lower().strip())\n",
        "            return plain\n",
        "\n",
        "        plain_thread = get_plain_thread(msg.content) + ' '\n",
        "        if msg.flags.has_thread:\n",
        "            async for m in msg.thread.history(limit=100, oldest_first=True):\n",
        "                formatted_content = m.content\n",
        "                plain_thread += get_plain_thread(formatted_content) + ' '\n",
        "        await ctx.respond(plain_thread)\n",
        "    except:\n",
        "        await ctx.respond(\"No message found.\")\n",
        "\n",
        "\n",
        "@bot.slash_command(name=\"keyword_search\", description=\"Search for messages containing a keyword\")\n",
        "async def search_messages(ctx: commands.Context, keyword: str):\n",
        "    channel = ctx.channel\n",
        "    messages = []\n",
        "    async for message in channel.history(limit=100):\n",
        "        if keyword in message.content:\n",
        "            messages.append(f\"{message.content}\\nURL: {message.jump_url}\")\n",
        "\n",
        "    if messages:\n",
        "        messages_str = \"\\n\".join(messages)\n",
        "\n",
        "        # 將訊息分割成多個部分，每個部分不超過 1000 字元\n",
        "        message_parts = [messages_str[i:i+1000] for i in range(0, len(messages_str), 1000)]\n",
        "        for part in message_parts:\n",
        "            await ctx.send(f\"Matching messages:\\n{part}\")\n",
        "    else:\n",
        "        await ctx.send(f\"No messages found containing '{keyword}'\")\n",
        "\n",
        "\n",
        "@bot.slash_command(name=\"savehistory\", description=\"Save chat history\")\n",
        "async def fetch(ctx: discord.ApplicationContext):\n",
        "\n",
        "    def is_command(msg): \n",
        "        \"\"\"Checking if the message is a command call\"\"\"\n",
        "        if len(msg.content) == 0:\n",
        "            return False\n",
        "        elif msg.content.split()[0] == '_scan':\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    data = []\n",
        "    async for msg in ctx.channel.history(limit=10000, oldest_first=True): \n",
        "        # if msg.author != ctx.user:                        \n",
        "        # if not is_command(msg):          \n",
        "        # Get root message\n",
        "        data.append({'content': msg.content,\n",
        "                    'created_at': msg.created_at,\n",
        "                    'author': msg.author.name,\n",
        "                    'jump_url': msg.jump_url,\n",
        "                    'author_id': msg.author.id,\n",
        "                    'msg_id': msg.id,\n",
        "                    'channel_id': msg.channel.id,\n",
        "                    'guild_id': msg.guild.id,\n",
        "                    })    \n",
        "        # Get thread messages (if any)\n",
        "        if msg.flags.has_thread:\n",
        "            async for thread_msg in msg.thread.history(limit=100, oldest_first=True):\n",
        "                data.append({'content': thread_msg.content,\n",
        "                            'created_at': thread_msg.created_at,\n",
        "                            'author': thread_msg.author.name,\n",
        "                            'jump_url': thread_msg.jump_url,\n",
        "                            'author_id': thread_msg.author.id,\n",
        "                            'msg_id': thread_msg.id,\n",
        "                            'channel_id': thread_msg.channel.id,\n",
        "                            'guild_id': thread_msg.guild.id,\n",
        "                            })\n",
        "            # if len(data) == limit:\n",
        "            #     break\n",
        "        \n",
        "    data = pd.DataFrame(data)\n",
        "    data.to_csv(CHAT_HISTORY_PATH)\n",
        "    await ctx.respond(\"Chat history saved!\")\n",
        "    print(f'Chat history saved to {CHAT_HISTORY_PATH}')\n",
        "\n",
        "\n",
        "bot.run(os.getenv('DISCORD_TOKEN'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9li8qtYRpAHZ",
        "outputId": "61c903b3-743d-4924-87de-1e60726a7658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetcher#2073 is ready and online!\n"
          ]
        }
      ],
      "source": [
        "!python3 fetcher.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = '1084864987887054919/1084864988688154627/1085661911934304337'\n",
        "guild_id, channel_id, msg_id = t.split('/')\n",
        "guild_id\n",
        "channel_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Khir7_9Lq1u5",
        "outputId": "782fac85-7b9d-4989-bcb7-235429346b22"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1084864988688154627'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjWpUYzYyX1z"
      },
      "source": [
        "# Deploy chat bot (won't do)\n",
        "FastAPI + Deta Space \n",
        "* [Deploy FastAPI on Deta](https://fastapi.tiangolo.com/deployment/deta/)\n",
        "* Also see section [deploy Qdrant vector search engine as a service](https://fastapi.tiangolo.com/deployment/deta/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS4oDRVNyoBN",
        "outputId": "1c18b0e6-ff47-4939-b663-429988ad0219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m794.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q \"fastapi[all]\" colab-xterm\n",
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaNLLCSv1uMc",
        "outputId": "5f10cac4-36a2-4c36-b1f5-03b50c0ae06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "######################################################################## 100.0%\n",
            "Archive:  /root/.detaspace/bin/space.zip\n",
            "  inflating: space                   \n",
            "Deta Space CLI was installed successfully to /root/.detaspace/bin/space\n",
            "Run 'space --help' in a new shell to get started\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://get.deta.dev/space-cli.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRuRmFrt4xau"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] += \":/root/.detaspace/bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e8tydVxsQ6t"
      },
      "outputs": [],
      "source": [
        "%xterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRWuLqJm-Z-d"
      },
      "outputs": [],
      "source": [
        "!mkdir fastapideta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39WSJVsc-1KQ",
        "outputId": "52040c1a-9646-4def-d5f0-768eaa00baf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./fastapideta/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./fastapideta/main.py\n",
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {'Hello': 'World'}\n",
        "\n",
        "@app.get(\"/items/{item_id}\")\n",
        "def read_item(item_id: int):\n",
        "    return {\"item_id\": item_id}\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiUwCA5X_bZj"
      },
      "outputs": [],
      "source": [
        "!touch ./fastapideta/requirements.txt\n",
        "!echo fastapi >> ./fastapideta/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqIYGOlc_x4Z"
      },
      "outputs": [],
      "source": [
        "# space new -d ./fastapideta\n",
        "# cd fastapideta/\n",
        "# space login\n",
        "# space new\n",
        "# space push\n",
        "# space release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx_EZwSvqUEi"
      },
      "source": [
        "# Set up Zoom Chat APIs (won't do)\n",
        "Won't do.\n",
        "\n",
        "* [Introduction to Zoom API](https://marketplace.zoom.us/docs/api-reference/introduction/)\n",
        "* [Zoom API authentication using OAuth](https://marketplace.zoom.us/docs/api-reference/using-zoom-apis/#using-oauth-20)\n",
        "* [Create a Server-to-Server OAuth app](https://marketplace.zoom.us/docs/guides/build/server-to-server-oauth-app/)\n",
        "* [Team Chatbot authentication](https://marketplace.zoom.us/docs/guides/team-chat-apps/installation-and-authentication/)\n",
        "* [Create a Team Chat App](https://marketplace.zoom.us/docs/guides/build/team-chat-app/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJGdbEGX14SR"
      },
      "source": [
        "Get access token from client secret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBxcQWOV2lww"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests\n",
        "base64.b64encode(b\"$ZM_CLIENT_ID:$ZM_CLIENT_SECRET\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcbZvWCUFaNR"
      },
      "outputs": [],
      "source": [
        "!cred=\"$( echo -n $ZM_CLIENT_ID:$ZM_CLIENT_SECRET | base64 )\"; echo $cred; "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6UZgwqLqV-b"
      },
      "outputs": [],
      "source": [
        "!curl -X POST 'https://zoom.us/oauth/token' -d 'grant_type=account_credentials' -H 'Host: zoom.us' -d \"account_id=$ZM_ACCOUNT_ID\" -H 'Authorization: Basic bUVtWlh0a3BSWGlUVU9WUjVlaUJWQTo1Y2R2TXNwVjRXNDVnT2g1dFhYNzBLM1FNZ1pOSkpsTw=='\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH3hgVQjEU4y"
      },
      "outputs": [],
      "source": [
        "token = {\"access_token\":\"eyJhbGciOiJIUzUxMiIsInYiOiIyLjAiLCJraWQiOiIxYzcxNDY4NS05OGMzLTRmNjgtYWVlYS0zNTk2YzBiZTVkMDIifQ.eyJ2ZXIiOjgsImF1aWQiOiJmNGZjZWIzZWYwODY2Y2M3YzFlZmY2Y2RjZjk4OGUwZiIsImNvZGUiOiJZalk5M2J5ZVNOLTh6cVpCc1B3dkd3WlBPdGRxZkRvb2QiLCJpc3MiOiJ6bTpjaWQ6bUVtWlh0a3BSWGlUVU9WUjVlaUJWQSIsImdubyI6MCwidHlwZSI6MywiYXVkIjoiaHR0cHM6Ly9vYXV0aC56b29tLnVzIiwidWlkIjoibzZvU1RqdFRSNmltYURmVDFJOVZZdyIsIm5iZiI6MTY3ODY3ODk3MSwiZXhwIjoxNjc4NjgyNTcxLCJpYXQiOjE2Nzg2Nzg5NzEsImFpZCI6Im1ZY2cwdllVVG9LQTVHN2ZIMVBiUmciLCJqdGkiOiI0YTljMDBhYS01ZTJhLTRkMzctOGYyNi1hY2E3YTZhZjc1ZWQifQ.ncagXMJlhHUHCm57u8HtXwb_9xaWArK--9uYEXQVWpFyCtUuDW_Zh3NAktTZp9hmgy8XKYDE6DhcLqowFR0qOg\",\"token_type\":\"bearer\",\"expires_in\":3599,\"scope\":\"chat_message:write:admin imchat:write:admin imchat:bot chat_channel:write:admin imchat:read:admin chat_channel:read:admin chat_message:read:admin\"}\n",
        "os.environ.setdefault('ACCESS_TOKEN', token['access_token'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-O4Tso5JtJ-"
      },
      "outputs": [],
      "source": [
        "!curl -X GET 'https://api.zoom.us/v2/chat/users/me/channels' -H 'HTTP/1.1' -H 'Host: zoom.us' -H \"Authorization: Bearer $ACCESS_TOKEN\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0JrOcOFGP5"
      },
      "outputs": [],
      "source": [
        "!curl -X GET 'https://api.zoom.us/v2/chat/users/me/messages?to_channel=61331c80faeb4cc89bf2c03bf8c14c6e' -H 'HTTP/1.1' -H 'Host: zoom.us' -H \"Authorization: Bearer $ACCESS_TOKEN\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOhYiAcmU6wJHhSeGHLi/Ka",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}